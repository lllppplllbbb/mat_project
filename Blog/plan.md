# 图像补全课题时间线与任务计划

## 1. 总体目标
在2025年11月前完成基于MAT的图像补全课题大部分工作，包括模型学习、开发、实验和论文初稿，确保学术创新性和外审通过率。

## 2. 时间线概览
- **2025年5月-6月**（学习与本地调试）：学习MAT，搭建环境，运行baseline。
- **2025年7月-8月**（创新点开发与服务器训练）：实现语义感知损失和自适应掩码，服务器训练PASCAL VOC子集。
- **2025年9月-10月**（扩展实验与论文撰写）：完成多场景实验，撰写论文初稿。
- **2025年11月**（收尾与外审准备）：整理代码，完善论文，准备外审材料。

## 3. 详细任务计划
### 阶段1：学习与本地调试（2025年5月-6月，8周）
- **目标**：掌握MAT架构，验证代码可运行性，搭建baseline。
- **任务**：
  - **5月1周-2周**（学习MAT）：
    - 阅读MAT论文（Li et al., CVPR 2022）和官方文档（https://github.com/dvlab-research/MAT）。
    - 理解Transformer块、Multi-head Contextual Attention和动态掩码机制。
    - 安装环境：PyTorch 1.9+，CUDA 11.x，GTX 1650。
  - **5月3周-4周**（数据准备与本地运行）：
    - 下载PASCAL VOC 2012（http://host.robots.ox.ac.uk/pascal/VOC/voc2012/）。
    - 抽取1,000张子集，生成随机掩码（10%-50%缺失率，Python+OpenCV）。
    - 运行MAT baseline（256x256，batch size=4），记录PSNR/SSIM。
    - 调试NaN问题（降低学习率至1e-5，梯度裁剪）。
  - **6月1周-2周**（语义感知损失初步实现）：
    - 集成SSIM和Perceptual Loss（基于预训练VGG，PyTorch torchvision）。
    - 对比MSE vs MSE+SSIM+Perceptual Loss，记录指标变化。
  - **6月3周-4周**（总结与准备服务器）：
    - 整理实验日志（Markdown格式，记录超参数、指标）。
    - 选择云服务（AWS/Google Cloud/阿里云），申请学术折扣。
    - 上传代码和数据，配置服务器环境（A100 GPU，PyTorch一致）。
- **成果**：
  - MAT baseline可运行，PASCAL VOC子集实验完成。
  - 语义感知损失初步实现，指标提升验证。
  - 服务器环境就绪。

### 阶段2：创新点开发与服务器训练（2025年7月-8月，8周）
- **目标**：实现语义引导自适应掩码，优化模型，完成PASCAL VOC训练。
- **任务**：
  - **7月1周-3周**（自适应掩码开发）：
    - 使用预训练DeepLabv3（PyTorch torchvision）生成语义分割图。
    - 修改MAT输入管道，基于分割图和注意力得分生成动态掩码。
    - 对比固定掩码 vs 动态掩码，记录PSNR/SSIM/FID。
  - **7月4周-8月2周**（服务器训练）：
    - 训练MAT+语义感知损失+自适应掩码（PASCAL VOC 1,000-2,000张，512x512，batch size=8-16，100-200 epochs）。
    - 优化超参数（学习率、损失权重），记录指标曲线。
    - 验证文物修复和自然场景修复效果（定性：可视化；定量：指标）。
  - **8月3周-4周**（初步对比实验 strenuous）：
    - 与DeepFillv2、LaMa对比（使用公开预训练模型）。
    - 整理消融实验（逐一验证损失函数和自适应掩码贡献）。
- **成果**：
  - 语义引导自适应掩码实现，PASCAL VOC实验完成。
  - 对比实验和消融实验数据齐全，指标提升显著。

### 阶段3：扩展实验与论文撰写（2025年9月-10月，8周）
- **目标**：完成多场景实验，撰写论文初稿。
- **任务**：
  - **9月1周-3周**（多场景实验）：
    - 抽取MS COCO子集（1,000张），测试自然场景和艺术品修复。
    - 验证模型泛化性，生成可视化结果（补全前后对比）。
    - 完成最终对比实验（MAT vs DeepFillv2/LaMa，PASCAL VOC+COCO）。
  - **9月4周-10月2周**（论文撰写）：
    - 撰写论文初稿（引言、相关工作、方法、实验、结论）。
    - 绘制指标曲线（PSNR/SSIM/FID），整理可视化结果。
    - 讨论局限性（如大面积缺失的挑战），提出未来工作。
- **成果**：
  - 多场景实验完成，泛化性验证。
  - 论文初稿（约70%完成），图表和实验数据齐全。

### 阶段4：收尾与外审准备（2025年11月，4周）
- **目标**：完善论文，公开代码，准备外审。
- **任务**：
  - **11月1周-2周**（代码整理）：
    - 整理代码，上传至GitHub（包括MAT修改、数据处理脚本）。
    - 提供详细README（环境配置、运行步骤）。
  - **11月3周-4周**（论文完善与外审准备）：
    - 完善论文，补充相关工作和讨论。
    - 准备外审答辩材料（PPT，实验日志）。
    - 提交论文初稿至导师，收集反馈。
- **成果**：
  - 代码公开，实验可复现。
  - 论文定稿，外审材料就绪。

## 4. 风险与应对
- **调试延迟**：若MAT baseline调试超2周，参考社区issue（https://github.com/dvlab-research/MAT/issues）或联系作者。
- **创新点超时**：若自适应掩码开发超3周，优先完成语义感知损失，推迟多模态引导。
- **服务器问题**：若成本超支，减少epoch（100以内）或冻结MAT预训练层。
- **论文质量**：若导师反馈需大幅修改，提前预留2周调整。

## 5. 进度跟踪
- **每周日志**：记录实验参数、指标、问题和解决方案（Markdown）。
- **每月总结**：更新进度，调整任务优先级，与导师同步。

## 6. 参考资源
- MAT源码：https://github.com/dvlab-research/MAT
- PASCAL VOC 2012：http://host.robots.ox.ac.uk/pascal/VOC/voc2012/
- DeepLabv3预训练模型：https://pytorch.org/vision/stable/models.html
- 预训练模型下载：OneDrive链接（见MAT仓库README）